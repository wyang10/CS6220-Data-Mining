# Heart Attack Risk Prediction ğŸ«€

Predicting in-hospital mortality for heart attack patients using classical machine learning models and class-imbalance techniques.

This repository contains a reproducible notebook, dataset, and report for a course project. We benchmark six classifiers and evaluate the impact of SMOTE on an imbalanced dataset (approx. 9:91).

Key takeaway: Decision Tree performed best among the baseline models; SMOTE substantially improved minority-class (DIED) recall.

Important note: This project is an academic exercise and is not intended for clinical use.

## Repository Structure

- `CS6220_Data_Mining_Final_Project.ipynb` â€” main analysis notebook (data prep, modeling, evaluation, visualization)
- `whole_table.csv` â€” dataset used in the notebook
- `data mining project.pdf`, `CS6220 - Data Mining Final Project.ipynb - Colaboratory.pdf` â€” writeup and PDF export
- `README.md` â€” project overview and instructions

## Dataset

Source: Provided as `whole_table.csv` for reproducibility. Columns include:

- `Patient` â€” anonymized identifier
- `DIAGNOSIS` â€” diagnosis code
- `SEX` â€” patient sex (`M`/`F`)
- `DRG` â€” diagnosis-related group code
- `DIED` â€” in-hospital mortality outcome (`1` = died, `0` = survived)
- `CHARGES` â€” total charges (some missing values may be `.`)
- `LOS` â€” length of stay (days)
- `AGE` â€” age in years

Class imbalance: The positive class (`DIED=1`) is rare (â‰ˆ9%).

## Models and Methods

train and compare the following models (scikit-learn):

- Naive Bayes (GaussianNB)
- K-Nearest Neighbors (KNN)
- Decision Tree
- Logistic Regression
- Support Vector Machine (SVM)
- Multi-layer Perceptron (Neural Network)

To address class imbalance, we apply SMOTE (from `imblearn`) and report metrics with and without SMOTE:

- Metrics: training/test accuracy, recall for both classes (with emphasis on `DIED` recall)

## Quick Start

1) Create an environment and install dependencies

```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

2) Launch Jupyter and run the notebook

```bash
jupyter notebook
# Open CS6220_Data_Mining_Final_Project.ipynb and run all cells
```

The notebook now loads the dataset with a repoâ€‘relative path (`whole_table.csv`) so it works out of the box.

Optional (headless execution):

```bash
jupyter nbconvert \
  --to notebook \
  --execute CS6220_Data_Mining_Final_Project.ipynb \
  --output CS6220_Data_Mining_Final_Project.executed.ipynb
```

## Results (Summary)

- Decision Tree achieved the strongest baseline performance on this dataset.
- SMOTE increased minority-class (DIED) recall across multiple models.
- Given the clinical context, prioritize recall for the positive class when selecting models.

For details, see the notebook and the included PDF report.

## Reproducibility Notes

- Random seeds are set in the notebook for model training where applicable.
- If you see parsing issues for `CHARGES` due to `.` values, convert to numeric with `errors="coerce"` and impute or drop as appropriate.

Example snippet:

```python
import pandas as pd
df = pd.read_csv("whole_table.csv")
df["CHARGES"] = pd.to_numeric(df["CHARGES"], errors="coerce")
```

## Disclaimer

This project is for educational purposes only and should not be used for clinical decisionâ€‘making.

## ä¸­æ–‡ç®€ä»‹

è¿™ä¸ªæ•°æ®æŒ–æ˜é¡¹ç›®ï¼Œä½¿ç”¨çº½çº¦å· 1993 å¹´å¿ƒæ¢—ä½é™¢æ‚£è€…æ•°æ®ï¼ŒåŸºäºäººå£å­¦ç‰¹å¾ä¸ä½é™¢ä¿¡æ¯ï¼Œæ¯”è¾ƒ 6 ç§ç»å…¸æœºå™¨å­¦ä¹ æ¨¡å‹å¯¹ä½é™¢æ­»äº¡çš„é¢„æµ‹èƒ½åŠ›ï¼Œå¹¶è¯„ä¼° SMOTE åœ¨ç±»åˆ«ä¸å¹³è¡¡ï¼ˆçº¦ 9:91ï¼‰åœºæ™¯ä¸‹çš„æ•ˆæœã€‚ä¸»è¦ç»“è®ºï¼šå†³ç­–æ ‘åœ¨åŸºçº¿æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ï¼›å¼•å…¥ SMOTE åï¼Œå°‘æ•°ç±»ï¼ˆæ­»äº¡ï¼‰å¬å›ç‡æ˜æ˜¾æå‡ã€‚ä»“åº“åŒ…å«å¯ç›´æ¥è¿è¡Œçš„ notebook ä¸æ•°æ®é›†ï¼Œå®‰è£… `requirements.txt` ååœ¨æœ¬åœ°å³å¯å¤ç°ã€‚
